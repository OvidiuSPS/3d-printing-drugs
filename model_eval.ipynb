{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the main dataset\n",
    "X = pd.read_csv('X.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "\n",
    "# Load the column names from the Excel files (assuming they are in the first row)\n",
    "padel_cols = pd.read_excel('Padel_cols.xlsx', header=None).iloc[0].dropna().tolist()\n",
    "spartan_cols = pd.read_excel('Spartan_cols.xlsx', header=None).iloc[0].dropna().tolist()\n",
    "swissadme_cols = pd.read_excel('Swissadme_cols.xlsx', header=None).iloc[0].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary ID'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "non_numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check rows with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nans(data):\n",
    "    rows_with_nans = data.isnull().any(axis=1)\n",
    "    num_rows_with_nans = rows_with_nans.sum()\n",
    "    total_rows = len(data)\n",
    "    fraction_rows_with_nans = num_rows_with_nans / total_rows\n",
    "\n",
    "    print(f\"Number of rows with NaNs: {num_rows_with_nans}\")\n",
    "    print(f\"Fraction of rows with NaNs: {fraction_rows_with_nans:.2f}\")\n",
    "\n",
    "    # Identify columns with NaNs\n",
    "    columns_with_nans = data.columns[data.isnull().any()].tolist()\n",
    "    num_columns_with_nans = len(columns_with_nans)\n",
    "\n",
    "    print(f\"Columns with NaNs: {columns_with_nans}\")\n",
    "\n",
    "    # Print detailed information about NaNs in each column\n",
    "    nan_info = data.isnull().sum()\n",
    "    print(\"\\nDetailed NaN information:\")\n",
    "    print(nan_info[nan_info > 0])\n",
    "    print(\"Number of columns with nan values:\")\n",
    "    print(f\"{num_columns_with_nans} columns out of the total {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NANs before standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 1444 columns\n",
      "NANs after standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 1079 columns\n",
      "NANs before standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 23 columns\n",
      "NANs after standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 23 columns\n",
      "NANs before standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 37 columns\n",
      "NANs after standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 35 columns\n",
      "Padel: 9 components retained\n",
      "Spartan: 7 components retained\n",
      "SwissADME: 7 components retained\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def perform_pca(X_subset, explained_variance_threshold=0.95):\n",
    "    # Print data nans before standardization\n",
    "    print(\"NANs before standardization\")\n",
    "    check_nans(X_subset)\n",
    "\n",
    "    # Drop zero variance columns\n",
    "    zero_variance_columns = X_subset.loc[:, X_subset.std() == 0].columns\n",
    "    X_subset = X_subset.drop(columns=zero_variance_columns)\n",
    "    \n",
    "    # Standardize the data if necessary\n",
    "    X_standardized = (X_subset - X_subset.mean()) / X_subset.std()\n",
    "\n",
    "    # Print data nans before standardization\n",
    "    print(\"NANs after standardization\")\n",
    "    check_nans(X_standardized)\n",
    "\n",
    "    # Initialize PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # Fit PCA\n",
    "    pca.fit(X_standardized)\n",
    "\n",
    "    # Calculate cumulative explained variance\n",
    "    cum_var_explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # Determine the number of components needed to reach the explained variance threshold\n",
    "    num_components = np.argmax(cum_var_explained >= explained_variance_threshold) + 1\n",
    "    \n",
    "    # Apply PCA with the selected number of components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    X_pca = pca.fit_transform(X_standardized)\n",
    "    \n",
    "    return X_pca, num_components, pca.explained_variance_ratio_\n",
    "\n",
    "# Perform PCA on each set of columns\n",
    "X_padel_pca, padel_n_components, padel_variance_ratio = perform_pca(X[padel_cols])\n",
    "X_spartan_pca, spartan_n_components, spartan_variance_ratio = perform_pca(X[spartan_cols])\n",
    "X_swissadme_pca, swissadme_n_components, swissadme_variance_ratio = perform_pca(X[swissadme_cols])\n",
    "\n",
    "# Display the number of components retained\n",
    "print(f\"Padel: {padel_n_components} components retained\")\n",
    "print(f\"Spartan: {spartan_n_components} components retained\")\n",
    "print(f\"SwissADME: {swissadme_n_components} components retained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing PCA, merge the datasets back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (1607, 28)\n",
      "                    0          1         2          3         4          5  \\\n",
      "Primary ID                                                                   \n",
      "BCS1_S1     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S1     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S2     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S2     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S3     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "...               ...        ...       ...        ...       ...        ...   \n",
      "PS-S18      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S19      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S19      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S20      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S20      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "\n",
      "                   6          7          8         0  ...         2         3  \\\n",
      "Primary ID                                            ...                       \n",
      "BCS1_S1     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S1     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S2     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S2     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S3     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "...              ...        ...        ...       ...  ...       ...       ...   \n",
      "PS-S18      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S19      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S19      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S20      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S20      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "\n",
      "                   4         5         6  3PBT-Diam (mm)  3PBT-Radius (mm)  \\\n",
      "Primary ID                                                                   \n",
      "BCS1_S1    -1.066953 -0.196191 -0.480698            1.88             0.940   \n",
      "BCS1_S1    -1.066953 -0.196191 -0.480698            1.88             0.940   \n",
      "BCS1_S2    -1.066953 -0.196191 -0.480698            1.77             0.885   \n",
      "BCS1_S2    -1.066953 -0.196191 -0.480698            1.77             0.885   \n",
      "BCS1_S3    -1.066953 -0.196191 -0.480698            1.82             0.910   \n",
      "...              ...       ...       ...             ...               ...   \n",
      "PS-S18      3.470082 -1.939209  0.524936            1.83             0.915   \n",
      "PS-S19      3.470082 -1.939209  0.524936            1.89             0.945   \n",
      "PS-S19      3.470082 -1.939209  0.524936            1.89             0.945   \n",
      "PS-S20      3.470082 -1.939209  0.524936            1.77             0.885   \n",
      "PS-S20      3.470082 -1.939209  0.524936            1.77             0.885   \n",
      "\n",
      "            API %  Plast %  ST-Diam (mm)  \n",
      "Primary ID                                \n",
      "BCS1_S1         5      0.0          1.99  \n",
      "BCS1_S1         5      0.0          1.99  \n",
      "BCS1_S2         5      0.0          1.91  \n",
      "BCS1_S2         5      0.0          1.91  \n",
      "BCS1_S3         5      0.0          1.91  \n",
      "...           ...      ...           ...  \n",
      "PS-S18         25     15.0          1.92  \n",
      "PS-S19         25     15.0          1.84  \n",
      "PS-S19         25     15.0          1.84  \n",
      "PS-S20         25     15.0          1.90  \n",
      "PS-S20         25     15.0          1.90  \n",
      "\n",
      "[1607 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert PCA results to DataFrames with 'Primary ID' as the index\n",
    "X_padel_pca_df = pd.DataFrame(X_padel_pca, index=X['Primary ID'])\n",
    "X_spartan_pca_df = pd.DataFrame(X_spartan_pca, index=X['Primary ID'])\n",
    "X_swissadme_pca_df = pd.DataFrame(X_swissadme_pca, index=X['Primary ID'])\n",
    "\n",
    "# Ensure that the other features DataFrame is also indexed by 'Primary ID'\n",
    "other_features_cols = X.columns.difference(padel_cols + spartan_cols + swissadme_cols)\n",
    "X_other_features = X[other_features_cols].set_index('Primary ID')\n",
    "\n",
    "# Ensure that the target DataFrame is also indexed by 'Primary ID'\n",
    "y.set_index('Primary ID', inplace=True)\n",
    "\n",
    "# Merge the PCA-transformed data back together with the rest of the features\n",
    "X_final = pd.concat([X_padel_pca_df, X_spartan_pca_df, X_swissadme_pca_df, X_other_features], axis=1)\n",
    "\n",
    "# Make sure all the column names are strings\n",
    "X_final.columns = X_final.columns.astype(str)\n",
    "\n",
    "# Verify the final DataFrame shape and columns\n",
    "print(f\"Final DataFrame shape: {X_final.shape}\")\n",
    "print(X_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates in the column names between the 3 data sources (Padel, Spartan, SwissADME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BCS1_S1', 'BCS1_S1', 'BCS1_S2', 'BCS1_S2', 'BCS1_S3', 'BCS1_S3',\n",
       "       'BCS1_S4', 'BCS1_S4', 'BCS1_S6', 'BCS1_S6',\n",
       "       ...\n",
       "       'PS-S16', 'PS-S16', 'PS-S17', 'PS-S17', 'PS-S18', 'PS-S18', 'PS-S19',\n",
       "       'PS-S19', 'PS-S20', 'PS-S20'],\n",
       "      dtype='object', name='Primary ID', length=1607)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '0', '1', '2', '3', '4',\n",
       "       '5', '6', '0', '1', '2', '3', '4', '5', '6', '3PBT-Diam (mm)',\n",
       "       '3PBT-Radius (mm)', 'API %', 'Plast %', 'ST-Diam (mm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BCS1_S1', 'BCS1_S1', 'BCS1_S2', 'BCS1_S2', 'BCS1_S3', 'BCS1_S3',\n",
       "       'BCS1_S4', 'BCS1_S4', 'BCS1_S6', 'BCS1_S6',\n",
       "       ...\n",
       "       'PS-S16', 'PS-S16', 'PS-S17', 'PS-S17', 'PS-S18', 'PS-S18', 'PS-S19',\n",
       "       'PS-S19', 'PS-S20', 'PS-S20'],\n",
       "      dtype='object', name='Primary ID', length=1607)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Multiregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 13:55:23.012760: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-08-30 13:55:23.012790: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-08-30 13:55:23.012797: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-08-30 13:55:23.012820: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-30 13:55:23.012833: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "loaded_model = tf.keras.models.load_model('best_model3.keras')\n",
    "\n",
    "# # Load the hyperparameters from JSON\n",
    "# with open('best_hyperparameters.json', 'r') as json_file:\n",
    "#     loaded_hyperparameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Target: ST-Hardness (g), Mean Squared Error: 9075386202.976032, R² Score: -1079.238582061124\n",
      "Target: ST-Hardness (g), Variance: 8401279.452229852, Range: 12780.0\n",
      "Relative MSE (MSE/Variance): 1080.2385820611241\n",
      "Relative MSE (MSE/Range): 710124.1160388131\n",
      "\n",
      "Target: ST-Rigidity at 2% deformation (g), Mean Squared Error: 685568231679.7294, R² Score: -882924.873084427\n",
      "Target: ST-Rigidity at 2% deformation (g), Variance: 776473.1474962385, Range: 3905.0\n",
      "Relative MSE (MSE/Variance): 882925.873084427\n",
      "Relative MSE (MSE/Range): 175561647.0370626\n",
      "\n",
      "Target: ST-Rigidity at 4% deformation (g), Mean Squared Error: 834911166359.6881, R² Score: -165726.15402149802\n",
      "Target: ST-Rigidity at 4% deformation (g), Variance: 5037865.8300702125, Range: 9430.0\n",
      "Relative MSE (MSE/Variance): 165727.15402149802\n",
      "Relative MSE (MSE/Range): 88537769.49731581\n",
      "\n",
      "Target: ST-Peak stress (N/mp), Mean Squared Error: 390992460661970.0, R² Score: 0.9592414067671816\n",
      "Target: ST-Peak stress (N/mp), Variance: 9592884092651836.0, Range: 790229366.0\n",
      "Relative MSE (MSE/Variance): 0.04075859323281836\n",
      "Relative MSE (MSE/Range): 494783.51157854847\n",
      "\n",
      "Target: 3PBT-Hardness (g), Mean Squared Error: 97675191181.00203, R² Score: -513696.76260503876\n",
      "Target: 3PBT-Hardness (g), Variance: 190141.35994222833, Range: 2251.5\n",
      "Relative MSE (MSE/Variance): 513697.7626050387\n",
      "Relative MSE (MSE/Range): 43382274.5640693\n",
      "\n",
      "Target: 3PBT-Deformation at hardness (mm), Mean Squared Error: 24971657503.474274, R² Score: -12354863550.827736\n",
      "Target: 3PBT-Deformation at hardness (mm), Variance: 2.0212005902550056, Range: 10.280000000000001\n",
      "Relative MSE (MSE/Variance): 12354863551.827736\n",
      "Relative MSE (MSE/Range): 2429149562.5947733\n",
      "\n",
      "Target: 3PBT-Total work (mJ), Mean Squared Error: 392935226173.8121, R² Score: -709290217.0685931\n",
      "Target: 3PBT-Total work (mJ), Variance: 553.9837095791057, Range: 155.23\n",
      "Relative MSE (MSE/Variance): 709290218.0685931\n",
      "Relative MSE (MSE/Range): 2531309838.1357474\n",
      "\n",
      "Target: 3PBT-Maximum force (N), Mean Squared Error: 45921149219.2195, R² Score: -2514687371.490304\n",
      "Target: 3PBT-Maximum force (N), Variance: 18.26117620885161, Range: 22.0647\n",
      "Relative MSE (MSE/Variance): 2514687372.4903035\n",
      "Relative MSE (MSE/Range): 2081204331.7706337\n",
      "\n",
      "Target: 3PBT-Peak stress (N/mp), Mean Squared Error: 12675269205176.773, R² Score: -5.551570921779212\n",
      "Target: 3PBT-Peak stress (N/mp), Variance: 1934691596337.7144, Range: 7061285.0\n",
      "Relative MSE (MSE/Variance): 6.551570921779211\n",
      "Relative MSE (MSE/Range): 1795037.1929722102\n",
      "\n",
      "Target: 3PBT-Flexural stress (g/mmp) (Samaro 2021 Prasad 2019), Mean Squared Error: 946819312645.7721, R² Score: -566710849.7851044\n",
      "Target: 3PBT-Flexural stress (g/mmp) (Samaro 2021 Prasad 2019), Variance: 1670.7273406430754, Range: 199.24841693795707\n",
      "Relative MSE (MSE/Variance): 566710850.7851043\n",
      "Relative MSE (MSE/Range): 4751954003.933679\n",
      "\n",
      "Target: 3PBT-Flexural strain (%), Mean Squared Error: 837842989.1739025, R² Score: -20226091.978173006\n",
      "Target: 3PBT-Flexural strain (%), Variance: 41.423867183744335, Range: 84.96\n",
      "Relative MSE (MSE/Variance): 20226092.978173006\n",
      "Relative MSE (MSE/Range): 9861617.1042126\n",
      "\n",
      "Target: 3PBT-Breaking distance (mm), Mean Squared Error: 23973945069.724304, R² Score: -11861239890.434835\n",
      "Target: 3PBT-Breaking distance (mm), Variance: 2.0212005902550056, Range: 10.280000000000001\n",
      "Relative MSE (MSE/Variance): 11861239891.434834\n",
      "Relative MSE (MSE/Range): 2332095823.903142\n",
      "\n",
      "Target: 3PBT-Stiffness (N/mm) (Hu 2022), Mean Squared Error: 105739713550.06271, R² Score: -19536480598.33024\n",
      "Target: 3PBT-Stiffness (N/mm) (Hu 2022), Variance: 5.4124238504701685, Range: 12.47999164112566\n",
      "Relative MSE (MSE/Variance): 19536480599.33024\n",
      "Relative MSE (MSE/Range): 8472739132.42183\n",
      "\n",
      "\n",
      "Overall R^2 Score: 0.9575983489394614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 13:55:23.460081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Convert predictions and test set to DataFrame for consistency with your metric calculations\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=y_test.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=y_test.columns)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test_df, y_pred_df, multioutput='raw_values')  # MSE for each target\n",
    "r2_per_target = r2_score(y_test_df, y_pred_df, multioutput='raw_values')  # R² for each target\n",
    "r2_overall = r2_score(y_test_df, y_pred_df, multioutput='variance_weighted')  # Overall weighted R²\n",
    "\n",
    "# Calculate variance or range of each target for relative performance\n",
    "variance_targets = np.var(y_test_df, axis=0)  # Variance of each target in test set\n",
    "range_targets = np.ptp(y_test_df, axis=0)  # Range (max-min) of each target in test set\n",
    "\n",
    "# Print MSE, R² score, variance, and range for each target\n",
    "for target_name, mse_value, r2_value, variance_value, range_value in zip(y_test_df.columns, mse, r2_per_target, variance_targets, range_targets):\n",
    "    print(f\"Target: {target_name}, Mean Squared Error: {mse_value}, R² Score: {r2_value}\")\n",
    "    print(f\"Target: {target_name}, Variance: {variance_value}, Range: {range_value}\")\n",
    "    print(f\"Relative MSE (MSE/Variance): {mse_value/variance_value if variance_value != 0 else 'Undefined'}\")\n",
    "    print(f\"Relative MSE (MSE/Range): {mse_value/range_value if range_value != 0 else 'Undefined'}\\n\")\n",
    "\n",
    "# Print overall R² score\n",
    "print(f\"\\nOverall R^2 Score: {r2_overall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharma3D_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
