{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the main dataset\n",
    "X = pd.read_csv('X.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "\n",
    "# Load the column names from the Excel files (assuming they are in the first row)\n",
    "padel_cols = pd.read_excel('Padel_cols.xlsx', header=None).iloc[0].dropna().tolist()\n",
    "spartan_cols = pd.read_excel('Spartan_cols.xlsx', header=None).iloc[0].dropna().tolist()\n",
    "swissadme_cols = pd.read_excel('Swissadme_cols.xlsx', header=None).iloc[0].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary ID'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "non_numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check rows with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nans(data):\n",
    "    rows_with_nans = data.isnull().any(axis=1)\n",
    "    num_rows_with_nans = rows_with_nans.sum()\n",
    "    total_rows = len(data)\n",
    "    fraction_rows_with_nans = num_rows_with_nans / total_rows\n",
    "\n",
    "    print(f\"Number of rows with NaNs: {num_rows_with_nans}\")\n",
    "    print(f\"Fraction of rows with NaNs: {fraction_rows_with_nans:.2f}\")\n",
    "\n",
    "    # Identify columns with NaNs\n",
    "    columns_with_nans = data.columns[data.isnull().any()].tolist()\n",
    "    num_columns_with_nans = len(columns_with_nans)\n",
    "\n",
    "    print(f\"Columns with NaNs: {columns_with_nans}\")\n",
    "\n",
    "    # Print detailed information about NaNs in each column\n",
    "    nan_info = data.isnull().sum()\n",
    "    print(\"\\nDetailed NaN information:\")\n",
    "    print(nan_info[nan_info > 0])\n",
    "    print(\"Number of columns with nan values:\")\n",
    "    print(f\"{num_columns_with_nans} columns out of the total {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NANs before standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 1444 columns\n",
      "NANs after standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 1079 columns\n",
      "NANs before standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 23 columns\n",
      "NANs after standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 23 columns\n",
      "NANs before standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 37 columns\n",
      "NANs after standardization\n",
      "Number of rows with NaNs: 0\n",
      "Fraction of rows with NaNs: 0.00\n",
      "Columns with NaNs: []\n",
      "\n",
      "Detailed NaN information:\n",
      "Series([], dtype: int64)\n",
      "Number of columns with nan values:\n",
      "0 columns out of the total 35 columns\n",
      "Padel: 9 components retained\n",
      "Spartan: 7 components retained\n",
      "SwissADME: 7 components retained\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def perform_pca(X_subset, explained_variance_threshold=0.95):\n",
    "    # Print data nans before standardization\n",
    "    print(\"NANs before standardization\")\n",
    "    check_nans(X_subset)\n",
    "\n",
    "    # Drop zero variance columns\n",
    "    zero_variance_columns = X_subset.loc[:, X_subset.std() == 0].columns\n",
    "    X_subset = X_subset.drop(columns=zero_variance_columns)\n",
    "    \n",
    "    # Standardize the data if necessary\n",
    "    X_standardized = (X_subset - X_subset.mean()) / X_subset.std()\n",
    "\n",
    "    # Print data nans before standardization\n",
    "    print(\"NANs after standardization\")\n",
    "    check_nans(X_standardized)\n",
    "\n",
    "    # Initialize PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # Fit PCA\n",
    "    pca.fit(X_standardized)\n",
    "\n",
    "    # Calculate cumulative explained variance\n",
    "    cum_var_explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # Determine the number of components needed to reach the explained variance threshold\n",
    "    num_components = np.argmax(cum_var_explained >= explained_variance_threshold) + 1\n",
    "    \n",
    "    # Apply PCA with the selected number of components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    X_pca = pca.fit_transform(X_standardized)\n",
    "    \n",
    "    return X_pca, num_components, pca.explained_variance_ratio_\n",
    "\n",
    "# Perform PCA on each set of columns\n",
    "X_padel_pca, padel_n_components, padel_variance_ratio = perform_pca(X[padel_cols])\n",
    "X_spartan_pca, spartan_n_components, spartan_variance_ratio = perform_pca(X[spartan_cols])\n",
    "X_swissadme_pca, swissadme_n_components, swissadme_variance_ratio = perform_pca(X[swissadme_cols])\n",
    "\n",
    "# Display the number of components retained\n",
    "print(f\"Padel: {padel_n_components} components retained\")\n",
    "print(f\"Spartan: {spartan_n_components} components retained\")\n",
    "print(f\"SwissADME: {swissadme_n_components} components retained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing PCA, merge the datasets back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (1607, 28)\n",
      "                    0          1         2          3         4          5  \\\n",
      "Primary ID                                                                   \n",
      "BCS1_S1     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S1     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S2     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S2     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "BCS1_S3     15.040758  11.898574 -0.559357  -4.244448 -6.108275   5.193660   \n",
      "...               ...        ...       ...        ...       ...        ...   \n",
      "PS-S18      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S19      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S19      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S20      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "PS-S20      -6.372475   5.878233 -1.844172  11.395460  3.400629 -14.099519   \n",
      "\n",
      "                   6          7          8         0  ...         2         3  \\\n",
      "Primary ID                                            ...                       \n",
      "BCS1_S1     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S1     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S2     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S2     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "BCS1_S3     0.926405   6.627692  -2.188991  2.551021  ...  0.555247  1.003252   \n",
      "...              ...        ...        ...       ...  ...       ...       ...   \n",
      "PS-S18      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S19      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S19      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S20      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "PS-S20      8.185611  10.989569  13.954430 -0.832286  ...  1.610551 -3.133331   \n",
      "\n",
      "                   4         5         6  3PBT-Diam (mm)  3PBT-Radius (mm)  \\\n",
      "Primary ID                                                                   \n",
      "BCS1_S1    -1.066953 -0.196191 -0.480698            1.88             0.940   \n",
      "BCS1_S1    -1.066953 -0.196191 -0.480698            1.88             0.940   \n",
      "BCS1_S2    -1.066953 -0.196191 -0.480698            1.77             0.885   \n",
      "BCS1_S2    -1.066953 -0.196191 -0.480698            1.77             0.885   \n",
      "BCS1_S3    -1.066953 -0.196191 -0.480698            1.82             0.910   \n",
      "...              ...       ...       ...             ...               ...   \n",
      "PS-S18      3.470082 -1.939209  0.524936            1.83             0.915   \n",
      "PS-S19      3.470082 -1.939209  0.524936            1.89             0.945   \n",
      "PS-S19      3.470082 -1.939209  0.524936            1.89             0.945   \n",
      "PS-S20      3.470082 -1.939209  0.524936            1.77             0.885   \n",
      "PS-S20      3.470082 -1.939209  0.524936            1.77             0.885   \n",
      "\n",
      "            API %  Plast %  ST-Diam (mm)  \n",
      "Primary ID                                \n",
      "BCS1_S1         5      0.0          1.99  \n",
      "BCS1_S1         5      0.0          1.99  \n",
      "BCS1_S2         5      0.0          1.91  \n",
      "BCS1_S2         5      0.0          1.91  \n",
      "BCS1_S3         5      0.0          1.91  \n",
      "...           ...      ...           ...  \n",
      "PS-S18         25     15.0          1.92  \n",
      "PS-S19         25     15.0          1.84  \n",
      "PS-S19         25     15.0          1.84  \n",
      "PS-S20         25     15.0          1.90  \n",
      "PS-S20         25     15.0          1.90  \n",
      "\n",
      "[1607 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert PCA results to DataFrames with 'Primary ID' as the index\n",
    "X_padel_pca_df = pd.DataFrame(X_padel_pca, index=X['Primary ID'])\n",
    "X_spartan_pca_df = pd.DataFrame(X_spartan_pca, index=X['Primary ID'])\n",
    "X_swissadme_pca_df = pd.DataFrame(X_swissadme_pca, index=X['Primary ID'])\n",
    "\n",
    "# Ensure that the other features DataFrame is also indexed by 'Primary ID'\n",
    "other_features_cols = X.columns.difference(padel_cols + spartan_cols + swissadme_cols)\n",
    "X_other_features = X[other_features_cols].set_index('Primary ID')\n",
    "\n",
    "# Ensure that the target DataFrame is also indexed by 'Primary ID'\n",
    "y.set_index('Primary ID', inplace=True)\n",
    "\n",
    "# Merge the PCA-transformed data back together with the rest of the features\n",
    "X_final = pd.concat([X_padel_pca_df, X_spartan_pca_df, X_swissadme_pca_df, X_other_features], axis=1)\n",
    "\n",
    "# Make sure all the column names are strings\n",
    "X_final.columns = X_final.columns.astype(str)\n",
    "\n",
    "# Verify the final DataFrame shape and columns\n",
    "print(f\"Final DataFrame shape: {X_final.shape}\")\n",
    "print(X_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates in the column names between the 3 data sources (Padel, Spartan, SwissADME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BCS1_S1', 'BCS1_S1', 'BCS1_S2', 'BCS1_S2', 'BCS1_S3', 'BCS1_S3',\n",
       "       'BCS1_S4', 'BCS1_S4', 'BCS1_S6', 'BCS1_S6',\n",
       "       ...\n",
       "       'PS-S16', 'PS-S16', 'PS-S17', 'PS-S17', 'PS-S18', 'PS-S18', 'PS-S19',\n",
       "       'PS-S19', 'PS-S20', 'PS-S20'],\n",
       "      dtype='object', name='Primary ID', length=1607)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '0', '1', '2', '3', '4',\n",
       "       '5', '6', '0', '1', '2', '3', '4', '5', '6', '3PBT-Diam (mm)',\n",
       "       '3PBT-Radius (mm)', 'API %', 'Plast %', 'ST-Diam (mm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BCS1_S1', 'BCS1_S1', 'BCS1_S2', 'BCS1_S2', 'BCS1_S3', 'BCS1_S3',\n",
       "       'BCS1_S4', 'BCS1_S4', 'BCS1_S6', 'BCS1_S6',\n",
       "       ...\n",
       "       'PS-S16', 'PS-S16', 'PS-S17', 'PS-S17', 'PS-S18', 'PS-S18', 'PS-S19',\n",
       "       'PS-S19', 'PS-S20', 'PS-S20'],\n",
       "      dtype='object', name='Primary ID', length=1607)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Multiregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the model-building function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the number of layers\n",
    "    for i in range(hp.Int('num_layers', 4, 15)):  # Search between 4 and 15 layers\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=2048, step=32),  # Number of neurons in each layer\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(Dropout(hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)))  # Tune dropout rate between 0.0 and 0.5\n",
    "    \n",
    "    model.add(Dense(y_train.shape[1], activation='linear'))  # Output layer for regression\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])  # Tune the learning rate\n",
    "        ),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "dims: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 11:58:19.825865: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-08-28 11:58:19.825884: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-08-28 11:58:19.825889: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-08-28 11:58:19.825907: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-28 11:58:19.825918: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-08-28 11:58:19.834872: I tensorflow/core/common_runtime/placer.cc:125] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.834883: I tensorflow/core/common_runtime/placer.cc:125] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.834886: I tensorflow/core/common_runtime/placer.cc:125] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.847827: I tensorflow/core/common_runtime/placer.cc:125] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.847837: I tensorflow/core/common_runtime/placer.cc:125] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.848698: I tensorflow/core/common_runtime/placer.cc:125] resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.848705: I tensorflow/core/common_runtime/placer.cc:125] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.848708: I tensorflow/core/common_runtime/placer.cc:125] AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.849558: I tensorflow/core/common_runtime/placer.cc:125] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.849565: I tensorflow/core/common_runtime/placer.cc:125] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.849568: I tensorflow/core/common_runtime/placer.cc:125] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.851182: I tensorflow/core/common_runtime/placer.cc:125] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.851189: I tensorflow/core/common_runtime/placer.cc:125] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.851882: I tensorflow/core/common_runtime/placer.cc:125] resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.851887: I tensorflow/core/common_runtime/placer.cc:125] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.851891: I tensorflow/core/common_runtime/placer.cc:125] AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.852725: I tensorflow/core/common_runtime/placer.cc:125] input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2024-08-28 11:58:19.852731: I tensorflow/core/common_runtime/placer.cc:125] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.852733: I tensorflow/core/common_runtime/placer.cc:125] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.854202: I tensorflow/core/common_runtime/placer.cc:125] dims: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2024-08-28 11:58:19.854206: I tensorflow/core/common_runtime/placer.cc:125] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.854209: I tensorflow/core/common_runtime/placer.cc:125] Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.854211: I tensorflow/core/common_runtime/placer.cc:125] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.896919: I tensorflow/core/common_runtime/placer.cc:125] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.896930: I tensorflow/core/common_runtime/placer.cc:125] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.899319: I tensorflow/core/common_runtime/placer.cc:125] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2024-08-28 11:58:19.899327: I tensorflow/core/common_runtime/placer.cc:125] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras_tuner import Hyperband\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# Optional: Log device placement\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Set up the Keras Tuner\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='keras_tuner_results',\n",
    "    project_name='multi_output_regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to save the best model\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model2.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Perform hyperparameter search with Keras Tuner\n",
    "tuner.search(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Save the best hyperparameters to a JSON file\n",
    "best_hyperparameters_dict = best_hyperparameters.values\n",
    "with open('best_hyperparameters.json', 'w') as json_file:\n",
    "    json.dump(best_hyperparameters_dict, json_file)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "loaded_model = tf.keras.models.load_model('best_model2.keras')\n",
    "\n",
    "# # Load the hyperparameters from JSON\n",
    "# with open('best_hyperparameters.json', 'r') as json_file:\n",
    "#     loaded_hyperparameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 17:00:04.231532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: ST-Hardness (g), Mean Squared Error: 590032316.0026608, R² Score: -69.23124505709133\n",
      "Target: ST-Hardness (g), Variance: 8401279.452229852, Range: 12780.0\n",
      "Relative MSE (MSE/Variance): 70.23124505709133\n",
      "Relative MSE (MSE/Range): 46168.41283275906\n",
      "\n",
      "Target: ST-Rigidity at 2% deformation (g), Mean Squared Error: 1763081955.0897481, R² Score: -2269.628367220245\n",
      "Target: ST-Rigidity at 2% deformation (g), Variance: 776473.1474962385, Range: 3905.0\n",
      "Relative MSE (MSE/Variance): 2270.628367220245\n",
      "Relative MSE (MSE/Range): 451493.4584096666\n",
      "\n",
      "Target: ST-Rigidity at 4% deformation (g), Mean Squared Error: 4927993630.310088, R² Score: -977.1907253058795\n",
      "Target: ST-Rigidity at 4% deformation (g), Variance: 5037865.8300702125, Range: 9430.0\n",
      "Relative MSE (MSE/Variance): 978.1907253058796\n",
      "Relative MSE (MSE/Range): 522586.8112736043\n",
      "\n",
      "Target: ST-Peak stress (N/mp), Mean Squared Error: 6166651113663785.0, R² Score: 0.35716401302216827\n",
      "Target: ST-Peak stress (N/mp), Variance: 9592884092651836.0, Range: 790229366.0\n",
      "Relative MSE (MSE/Variance): 0.6428359869778317\n",
      "Relative MSE (MSE/Range): 7803621.807777497\n",
      "\n",
      "Target: 3PBT-Hardness (g), Mean Squared Error: 2214354267.344887, R² Score: -11644.831648714862\n",
      "Target: 3PBT-Hardness (g), Variance: 190141.35994222833, Range: 2251.5\n",
      "Relative MSE (MSE/Variance): 11645.83164871486\n",
      "Relative MSE (MSE/Range): 983501.7842970849\n",
      "\n",
      "Target: 3PBT-Deformation at hardness (mm), Mean Squared Error: 682823710.0945915, R² Score: -337830748.40050495\n",
      "Target: 3PBT-Deformation at hardness (mm), Variance: 2.0212005902550056, Range: 10.280000000000001\n",
      "Relative MSE (MSE/Variance): 337830749.40050495\n",
      "Relative MSE (MSE/Range): 66422539.89246998\n",
      "\n",
      "Target: 3PBT-Total work (mJ), Mean Squared Error: 11329056065.09635, R² Score: -20450160.02315302\n",
      "Target: 3PBT-Total work (mJ), Variance: 553.9837095791057, Range: 155.23\n",
      "Relative MSE (MSE/Variance): 20450161.02315302\n",
      "Relative MSE (MSE/Range): 72982387.84446532\n",
      "\n",
      "Target: 3PBT-Maximum force (N), Mean Squared Error: 5579811175.684535, R² Score: -305555956.1776036\n",
      "Target: 3PBT-Maximum force (N), Variance: 18.26117620885161, Range: 22.0647\n",
      "Relative MSE (MSE/Variance): 305555957.17760354\n",
      "Relative MSE (MSE/Range): 252884071.64767867\n",
      "\n",
      "Target: 3PBT-Peak stress (N/mp), Mean Squared Error: 8176320703711.155, R² Score: -3.2261623088602693\n",
      "Target: 3PBT-Peak stress (N/mp), Variance: 1934691596337.7144, Range: 7061285.0\n",
      "Relative MSE (MSE/Variance): 4.226162308860269\n",
      "Relative MSE (MSE/Range): 1157908.32740941\n",
      "\n",
      "Target: 3PBT-Flexural stress (g/mmp) (Samaro 2021 Prasad 2019), Mean Squared Error: 1447663955.7762933, R² Score: -866486.2601049772\n",
      "Target: 3PBT-Flexural stress (g/mmp) (Samaro 2021 Prasad 2019), Variance: 1670.7273406430754, Range: 199.24841693795707\n",
      "Relative MSE (MSE/Variance): 866487.2601049772\n",
      "Relative MSE (MSE/Range): 7265623.376205161\n",
      "\n",
      "Target: 3PBT-Flexural strain (%), Mean Squared Error: 3373133284.830048, R² Score: -81429704.00237945\n",
      "Target: 3PBT-Flexural strain (%), Variance: 41.423867183744335, Range: 84.96\n",
      "Relative MSE (MSE/Variance): 81429705.00237945\n",
      "Relative MSE (MSE/Range): 39702604.57662486\n",
      "\n",
      "Target: 3PBT-Breaking distance (mm), Mean Squared Error: 607304900.1928344, R² Score: -300467405.90700746\n",
      "Target: 3PBT-Breaking distance (mm), Variance: 2.0212005902550056, Range: 10.280000000000001\n",
      "Relative MSE (MSE/Variance): 300467406.90700746\n",
      "Relative MSE (MSE/Range): 59076352.15883602\n",
      "\n",
      "Target: 3PBT-Stiffness (N/mm) (Hu 2022), Mean Squared Error: 36506850.97887213, R² Score: -6745008.627378099\n",
      "Target: 3PBT-Stiffness (N/mm) (Hu 2022), Variance: 5.4124238504701685, Range: 12.47999164112566\n",
      "Relative MSE (MSE/Variance): 6745009.6273781\n",
      "Relative MSE (MSE/Range): 2925230.403085375\n",
      "\n",
      "\n",
      "Overall R^2 Score: 0.35643808229141266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Convert predictions and test set to DataFrame for consistency with your metric calculations\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=y_test.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=y_test.columns)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test_df, y_pred_df, multioutput='raw_values')  # MSE for each target\n",
    "r2_per_target = r2_score(y_test_df, y_pred_df, multioutput='raw_values')  # R² for each target\n",
    "r2_overall = r2_score(y_test_df, y_pred_df, multioutput='variance_weighted')  # Overall weighted R²\n",
    "\n",
    "# Calculate variance or range of each target for relative performance\n",
    "variance_targets = np.var(y_test_df, axis=0)  # Variance of each target in test set\n",
    "range_targets = np.ptp(y_test_df, axis=0)  # Range (max-min) of each target in test set\n",
    "\n",
    "# Print MSE, R² score, variance, and range for each target\n",
    "for target_name, mse_value, r2_value, variance_value, range_value in zip(y_test_df.columns, mse, r2_per_target, variance_targets, range_targets):\n",
    "    print(f\"Target: {target_name}, Mean Squared Error: {mse_value}, R² Score: {r2_value}\")\n",
    "    print(f\"Target: {target_name}, Variance: {variance_value}, Range: {range_value}\")\n",
    "    print(f\"Relative MSE (MSE/Variance): {mse_value/variance_value if variance_value != 0 else 'Undefined'}\")\n",
    "    print(f\"Relative MSE (MSE/Range): {mse_value/range_value if range_value != 0 else 'Undefined'}\\n\")\n",
    "\n",
    "# Print overall R² score\n",
    "print(f\"\\nOverall R^2 Score: {r2_overall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharma3D_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
